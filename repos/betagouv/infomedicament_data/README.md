# Extraction de donnÃ©es RCP - Module complet

Module d'extraction automatisÃ©e de donnÃ©es depuis les fichiers RCP (RÃ©sumÃ© des CaractÃ©ristiques du Produit) de mÃ©dicaments avec architecture modulaire et scripts spÃ©cialisÃ©s.

## ğŸ¯ Objectif

Extraire et structurer les informations mÃ©dicales depuis les fichiers HTML RCP pour faciliter l'analyse, l'export vers diffÃ©rents formats, et l'intÃ©gration dans des pipelines de donnÃ©es.

## ğŸ“ Architecture du projet

```
extraction/
â”œâ”€â”€ ğŸ“¦ MODULES PYTHON (refactorisÃ©s)
â”‚   â”œâ”€â”€ __init__.py              # Package principal
â”‚   â”œâ”€â”€ html_parser.py           # Parsing HTML avec dÃ©tection encodage
â”‚   â”œâ”€â”€ database.py              # Interface MySQL optimisÃ©e
â”‚   â”œâ”€â”€ image_processor.py       # Traitement images et URLs
â”‚   â”œâ”€â”€ data_exporter.py         # Export multi-format (CSV, JSONL)
â”‚   â”œâ”€â”€ analytics.py             # Analyse statistiques Matomo
â”‚   â”œâ”€â”€ extractor.py             # Orchestrateur principal
â”‚   â””â”€â”€ cli.py                   # Interface ligne de commande
â”‚
â”œâ”€â”€ ğŸ§ª TESTS UNITAIRES
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”œâ”€â”€ test_html_parser.py
â”‚   â”‚   â”œâ”€â”€ test_image_processor.py
â”‚   â”‚   â””â”€â”€ test_database.py
â”‚
â”œâ”€â”€ ğŸ“Š DONNÃ‰ES
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ input/               # SpecIds, analytics
â”‚   â”‚   â”œâ”€â”€ output/              # Extractions, rapports
â”‚   â”‚   â”œâ”€â”€ processed/           # DonnÃ©es intermÃ©diaires
â”‚   â”‚   â””â”€â”€ archive/             # DonnÃ©es archivÃ©es
â”‚
â”œâ”€â”€ ğŸ““ NOTEBOOKS EXPLORATION
â”‚   â”œâ”€â”€ notebooks/
â”‚   â”‚   â”œâ”€â”€ extractRCPFull.ipynb       # Exploration RCP
â”‚   â”‚   â”œâ”€â”€ extractFicheInfo.ipynb     # Fiches mÃ©dicaments
â”‚   â”‚   â”œâ”€â”€ extractNotices.ipynb       # Notices patient
â”‚   â”‚   â”œâ”€â”€ extractSubstancesMarr.ipynb # Substances actives
â”‚   â”‚   â””â”€â”€ scrap-marr.ipynb           # Scraping donnÃ©es
â”‚
â”œâ”€â”€ ğŸ› ï¸ SCRIPTS SPÃ‰CIALISÃ‰S
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â””â”€â”€ final/               # Scripts production finalisÃ©s
â”‚   â”‚       â”œâ”€â”€ extract-rcp.py           # Extraction RCP avancÃ©e
â”‚   â”‚       â”œâ”€â”€ extract-fiches-infos.py  # Fiches batch optimisÃ©
â”‚   â”‚       â”œâ”€â”€ extract-matomo.py        # Export Matomo
â”‚   â”‚       â”œâ”€â”€ detect-duplicate-content.py  # DÃ©tection doublons
â”‚   â”‚       â”œâ”€â”€ duplicate-rcp-analysis.py    # Analyse duplicatas
â”‚   â”‚       â””â”€â”€ filter_5000.py          # Filtrage top mÃ©dicaments
â”‚
â”œâ”€â”€ ğŸ—‚ï¸ LEGACY (scripts obsolÃ¨tes)
â”‚   â”œâ”€â”€ legacy/
â”‚   â”‚   â”œâ”€â”€ extractRcp.py        # RemplacÃ© par cli extract
â”‚   â”‚   â”œâ”€â”€ extractRcpMulti.py   # RemplacÃ© par cli extract --extended
â”‚   â”‚   â”œâ”€â”€ export_most_viewed.py # RemplacÃ© par cli analytics
â”‚   â”‚   â””â”€â”€ extractSubstances5000.py # RemplacÃ© par cli components
â”‚
â”œâ”€â”€ ğŸ“š DOCUMENTATION
â”‚   â”œâ”€â”€ docs/
â”‚   â”‚   â””â”€â”€ architecture.md      # Architecture technique dÃ©taillÃ©e
â”‚   â”œâ”€â”€ README.md                # Ce fichier
â”‚   â”œâ”€â”€ pyproject.toml           # Configuration projet
â”‚   â”œâ”€â”€ .env.example             # Variables d'environnement
â”‚   â””â”€â”€ .gitignore               # Exclusions Git
```

## ğŸš€ Installation et usage rapide

### Installation

On utilise :
- Python3.12+
- Poetry (Install via pipx install poetry or follow the official guide)

```bash
# Install dependencies and project into a virtual environment
poetry install
```

### Usage CLI principal

```bash
# 1. Extraction basique vers JSONL
poetry run extraction-cli extract /path/to/html_folder/ -o export.jsonl

# 2. Extraction vers CSV avec traitement parallÃ¨le
poetry run extraction-cli extract /path/to/html -f csv --csv-format extended -o export.csv --processes 4

# 3. Extraction composants pour liste SpecIds
poetry run extraction-cli components spec_ids.txt -o composants.csv

# 4. Analyse top consultÃ©s (80% couverture)
poetry run extraction-cli analytics consultations.csv -c 80 -o top_specs.txt

# 5. GÃ©nÃ©ration rapport analytics
poetry run extraction-cli report consultations.csv -o rapport.md
```

(Vous pouvez vous Ã©pargner le `poetry run` en rentrant dans votre venv via `$(poetry env info --path)/bin/activate`)

### Usage API Python
```python
from extraction import RCPExtractor, DatabaseConfig
from pathlib import Path

# Configuration et extraction
db_config = DatabaseConfig()
extractor = RCPExtractor(
    db_config=db_config,
    html_dir=Path("/html/files"),
    enable_images=True,
    max_workers=4
)

# Extraction complÃ¨te
data = extractor.extract_to_jsonl(
    output_file=Path("rcp_data.jsonl"),
    limit=1000
)
```

## ğŸ”„ Migration depuis scripts legacy

### Correspondances des commandes

| Script legacy | Commande moderne | Notes |
|---------------|------------------|-------|
| `extractRcp.py /html -f csv -o out.csv` | `extraction-cli extract /html -f csv -o out.csv` | Format basique identique |
| `extractRcpMulti.py /html -f csv -p 4` | `extraction-cli extract /html -f csv --csv-format extended --processes 4` | Format Ã©tendu + parallÃ©lisme |
| `export_most_viewed.py stats.csv 80 out.txt` | `extraction-cli analytics stats.csv -c 80 -o out.txt` | Analytics avec couverture |
| `extractSubstances5000.py ids.txt out.csv` | `extraction-cli components ids.txt -o out.csv` | Extraction composants |

### Avantages de la migration

âœ… **Architecture modulaire** vs scripts monolithiques
âœ… **Tests unitaires** vs aucune validation
âœ… **Configuration centralisÃ©e** vs paramÃ¨tres hardcodÃ©s
âœ… **Gestion d'erreurs robuste** vs crash sur erreur
âœ… **Documentation complÃ¨te** vs commentaires Ã©pars
âœ… **Performance optimisÃ©e** vs implÃ©mentation naÃ¯ve

## ğŸ“Š FonctionnalitÃ©s principales

### ğŸ” Extraction RCP
- **Parsing HTML robuste** avec dÃ©tection d'encodage automatique
- **Extraction sections** : SÃ©curitÃ© prÃ©clinique, prÃ©cautions d'emploi, contre-indications
- **Traitement images** : Conversion URLs relatives â†’ absolues
- **MÃ©tadonnÃ©es** : CIS, dÃ©nomination, code ATC, composants
- **Formats sortie** : JSONL structurÃ©, CSV basique/Ã©tendu

### ğŸ“ˆ Analytics et statistiques
- **Analyse Matomo** : Parsing donnÃ©es de consultation
- **Couverture traffic** : Extraction par seuil de pourcentage
- **Top mÃ©dicaments** : Listes des plus consultÃ©s
- **Rapports visuels** : GÃ©nÃ©ration automatique

### ğŸ§¬ Composants et substances
- **Extraction dÃ©duplication** : SubsId et NomLib uniques
- **Optimisation base** : RequÃªtes par batch
- **Relations complexes** : SpecId â†’ Composants â†’ Substances
- **Export normalisÃ©** : CSV avec mapping complet

### ğŸ› ï¸ Outils spÃ©cialisÃ©s
- **DÃ©tection doublons** : Analyse similaritÃ© contenus
- **Validation donnÃ©es** : ContrÃ´les qualitÃ© automatisÃ©s
- **Pipeline ETL** : IntÃ©gration flux de donnÃ©es
- **Monitoring** : MÃ©triques performance et erreurs

## ğŸ›ï¸ Configuration avancÃ©e

### Variables d'environnement
```bash
# Base de donnÃ©es
export DB_HOST=localhost
export DB_USER=root
export DB_PASSWORD=mysql
export DB_NAME=pdbm_bdd

# Chemins
export HTML_FILES_DIR=/path/to/html/files
export OUTPUT_DIR=/path/to/outputs

# Performance
export MAX_WORKERS=4
export ENABLE_IMAGES=true
export BATCH_SIZE=100
```

### Configuration base MySQL
```sql
-- Structure requise
CREATE TABLE Spec_Doc (SpecId INT, DocId INT);
CREATE TABLE Document (DocId INT, DocPath VARCHAR(255));
CREATE TABLE Composant (SpecId INT, SubsId VARCHAR(50), NomId INT);
CREATE TABLE Subs_Nom (SubsId VARCHAR(50), NomId INT, NomLib VARCHAR(255));
CREATE TABLE Element (SpecId INT, ElmtNom VARCHAR(255));
```

## ğŸ§ª Tests et qualitÃ©

### ExÃ©cution des tests
```bash
# Tous les tests
pytest tests/

# Tests spÃ©cifiques avec couverture
pytest tests/test_html_parser.py --cov=extraction.html_parser

# Tests avec rapport HTML
pytest tests/ --cov=extraction --cov-report=html
```

### Outils qualitÃ©
```bash

# Linting et formattage
ruff check
ruff format

# Type checking (optionnel)
mypy extraction/
```

## ğŸ“ˆ Performance et optimisations

### MÃ©triques typiques
- **Parsing HTML** : ~500 fichiers/minute
- **Extraction complÃ¨te sÃ©quentielle** : ~100 RCP/minute
- **Extraction parallÃ¨le (4 workers)** : ~400 RCP/minute
- **Analytics processing** : ~10K entrÃ©es/seconde

### Optimisations recommandÃ©es
- **Traitement parallÃ¨le** : `--processes` selon CPU disponibles
- **Cache mappings** : Chargement unique des tables de rÃ©fÃ©rence
- **Limitation mÃ©moire** : `--limit` pour gros volumes
- **Compression sortie** : gzip pour fichiers volumineux

## ğŸ”— IntÃ©gration et extensibilitÃ©

### Nouveaux formats d'export
```python
class CustomExporter(DataExporter):
    def export_to_xml(self, data_list, output_file):
        # ImplÃ©mentation export XML
        pass
```

### Nouvelles sections RCP
```python
class ExtendedRCPParser(RCPParser):
    def __init__(self):
        super().__init__()
        self.sections_map.update({
            'RcpNouvelleSection': 'nouvelle_section'
        })
```

### Pipelines de donnÃ©es
```bash
#!/bin/bash
# Pipeline quotidien automatisÃ©
DATE=$(date +%Y%m%d)

# Extraction
extraction-cli extract /html/files -o data/output/rcp_${DATE}.jsonl

# Analytics
extraction-cli analytics data/input/matomo_${DATE}.csv -c 80 -o data/output/top_${DATE}.txt

# Archive
gzip data/output/rcp_${DATE}.jsonl
```

## ğŸ“‹ Roadmap et Ã©volutions

### Version actuelle (1.0)
âœ… Module extraction complet
âœ… CLI interface complÃ¨te
âœ… Tests unitaires de base
âœ… Documentation architecture

### Versions futures

#### v1.1 - AmÃ©lioration performance
- [ ] Optimisation parsing HTML
- [ ] Cache disque pour mappings
- [ ] Streaming pour gros volumes
- [ ] MÃ©triques dÃ©taillÃ©es

#### v1.2 - FonctionnalitÃ©s avancÃ©es
- [ ] Support nouveaux formats (XML, Parquet)
- [ ] API REST pour intÃ©gration
- [ ] Dashboard monitoring temps rÃ©el
- [ ] Validation donnÃ©es automatisÃ©e

#### v1.3 - Intelligence artificielle
- [ ] Classification automatique sections
- [ ] DÃ©tection anomalies contenu
- [ ] Extraction entitÃ©s nommÃ©es
- [ ] Suggestions amÃ©lioration qualitÃ©

## ğŸ†˜ Support et contribution

### ProblÃ¨mes courants
- **Erreur connexion MySQL** : VÃ©rifier configuration DB
- **Fichiers HTML corrompus** : Utiliser `--enable-images false`
- **Performance lente** : Augmenter `--processes`
- **Erreurs encoding** : VÃ©rifier fichiers source

### Contribution
1. **Issues** : Reporter bugs et demandes fonctionnalitÃ©s
2. **Pull requests** : AmÃ©liorations et corrections
3. **Documentation** : Mises Ã  jour et exemples
4. **Tests** : Couverture de nouveaux cas

### Contact
- **Documentation** : `docs/architecture.md`
- **Issues** : GitHub repository
- **Tests** : `pytest tests/ -v`
- **Code** : `extraction/` modules