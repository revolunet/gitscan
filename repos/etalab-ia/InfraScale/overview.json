{
  "url": "https://github.com/etalab-ia/InfraScale",
  "name": "InfraScale",
  "description": "InfraScale est un outil développé par l'équipe Albert API pour estimer les besoins en GPU pour l'inférence LLM à grande échelle. Il fournit une méthodologie reproductible, ouverte et pratique pour estimer les besoins en GPU.",
  "language": "Python",
  "features": [
    "Estimation des besoins en GPU",
    "Calcul de la mémoire requise",
    "Optimisation des ressources",
    "Analyse des performances"
  ],
  "audience": "Professionnels",
  "dependencies": [
    "streamlit",
    "numpy",
    "pandas",
    "Jinja2",
    "jsonschema",
    "protobuf",
    "grpcio",
    "pyarrow"
  ],
  "components": [
    "Frontend Streamlit",
    "Backend Python",
    "Modèles d'estimation",
    "Base de données JSON (gpu.json, models.json)"
  ],
  "auth": {
    "methods": [
      "none"
    ]
  },
  "tests": [
    "Notebooks Jupyter (calibration.ipynb, solver.ipynb)"
  ],
  "workflows": [],
  "lastActivity": "2025-09-21T10:16:21Z",
  "status": "active",
  "license": null,
  "hasDocumentation": true,
  "metrics": {
    "stars": 7,
    "forks": 1,
    "contributors": null,
    "openIssues": 0
  },
  "tags": [
    "LLM",
    "GPU",
    "Inference",
    "Scalability",
    "Estimation",
    "Machine Learning",
    "Streamlit",
    "Python"
  ]
}
