{
  "url": "https://github.com/etalab-ia/albert-conversation",
  "name": "albert-conversation",
  "description": "Open WebUI est une plateforme d'IA auto-hébergée, extensible et conviviale, conçue pour fonctionner entièrement hors ligne. Elle prend en charge divers runners LLM comme Ollama et des API compatibles OpenAI, avec un moteur d'inférence intégré pour RAG.",
  "language": "Python",
  "features": [
    "Authentification utilisateur",
    "Recherche",
    "Génération d'images",
    "Intégration de modèles",
    "Chat multi-modèles",
    "RAG (Retrieval Augmented Generation)",
    "Traduction",
    "Appel de fonctions",
    "Recherche Web",
    "Prise en charge Markdown et LaTeX",
    "Appels vocaux/vidéo"
  ],
  "audience": "Professionnels",
  "dependencies": [
    "React",
    "FastAPI",
    "Uvicorn",
    "Pydantic",
    "Ollama",
    "OpenAI",
    "Langchain",
    "Transformers",
    "PyTorch",
    "Redis",
    "Docker"
  ],
  "components": [
    "Frontend React",
    "Backend Python (FastAPI)",
    "Base de données (PostgreSQL, Redis)",
    "API REST",
    "Moteur d'inférence RAG"
  ],
  "auth": {
    "methods": [
      "oauth2",
      "session"
    ],
    "providers": []
  },
  "tests": "Pytest, Cypress",
  "workflows": [],
  "lastActivity": "2025-04-14T00:00:00Z",
  "status": "active",
  "license": "BSD-3-Clause License",
  "hasDocumentation": true,
  "metrics": null,
  "tags": [
    "IA",
    "LLM",
    "RAG",
    "Open Source",
    "Python",
    "Docker",
    "Ollama",
    "OpenAI",
    "Chatbot",
    "Auto-hébergé"
  ]
}
